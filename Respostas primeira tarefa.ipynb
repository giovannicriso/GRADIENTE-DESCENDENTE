{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fe5f47",
   "metadata": {},
   "source": [
    "Ex 1: \n",
    "\n",
    "A função é uma parabola com concavidade para cima e o algoritmo sempre converge para o mínimo global desde que alpha não seja excessivamente grande. Uma taxa de aprendizado muito alta pode causar instabilidades, fazendo o ponto ir para o outro extremo da parabola, porém o mínimo é alcançado na maioria dos casos.\n",
    "Na imagem abaixo, temos a implementação do gradiente descendente para encontrar o minimo da função. Nota que os pontos azuis correspondem a passos cujos parametros alpha são pequeno e os vermelhos temos valores de alpha grandes.\n",
    "\n",
    "![Imagem1](EX1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10067969",
   "metadata": {},
   "source": [
    "Ex 2: \n",
    "\n",
    "O gráfico acima ilustra a aplicação do gradiente descendente na função \\( f_2(x) = x^4 - x^2 \\). A curva verde representa a função a ser minimizada. Observa-se que, para um valor pequeno de alpha (pontos azuis), o algoritmo converge de forma lenta, porém estável, até um mínimo local. Já para valores altos de \\( \\alpha \\) (pontos vermelhos), a trajetória se torna instável, com oscilações e desvios significativos. \n",
    "\n",
    "Além disso, como a função possui mais de um ponto de mínimo, a **posição inicial** influencia fortemente o resultado final: dependendo de onde o algoritmo começa, ele pode convergir para diferentes mínimos locais — ou até mesmo não convergir, caso a taxa de aprendizado seja muito alta e cause saltos excessivos.\n",
    "\n",
    "![Imagem2](ex2.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af872c",
   "metadata": {},
   "source": [
    "Ex 3: \n",
    "\n",
    "Ao adicionarmos o termo linear à função, ela deixa de ser simétrica e um dos mínimos torna-se mais profundo — passando a ser o **mínimo global**. Isso altera significativamente o comportamento do gradiente descendente.\n",
    "\n",
    "Notamos que, ao variar o valor de alpha, há uma mudança importante na convergência:\n",
    "- Para valores **grandes de alpha**, os passos são largos e, muitas vezes, a trajetória consegue \"saltar\" sobre o mínimo local e atingir o **mínimo global**.\n",
    "- Já com valores **pequenos de alpha**, os passos são curtos, o que torna o algoritmo mais suscetível a ficar preso no **mínimo local mais próximo da posição inicial**.\n",
    "\n",
    "Além disso, o **número de passos (iterações)** também influencia o resultado final: dependendo do tamanho dos saltos e da inclinação da função ao longo do caminho, o algoritmo pode terminar em diferentes mínimos. Ou seja, tanto a taxa de aprendizado quanto a quantidade de iterações são fatores cruciais para determinar o ponto de convergência.\n",
    "\n",
    "\n",
    "![Imagem3](ex3.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fedb796",
   "metadata": {},
   "source": [
    "Ex 4: \n",
    "\n",
    "### Gráfico de Contorno com Trajetória (à esquerda)\n",
    "\n",
    "Este gráfico mostra as curvas de nível da função \\( U(x, y) \\), representando seu relevo.  \n",
    "A linha vermelha indica a trajetória percorrida pelo algoritmo de gradiente descendente a partir do ponto inicial.  \n",
    "Se a trajetória for suave e converge para um ponto estável, isso indica que o algoritmo está funcionando corretamente e aproximando-se de um mínimo da função.\n",
    "\n",
    "\n",
    "### Gráfico da Evolução de \\( U(x_n, y_n) \\) (à direita)\n",
    "\n",
    "Este gráfico mostra como o valor da função \\( U \\) varia ao longo das iterações.  \n",
    "Uma curva decrescente e que se estabiliza sugere que o algoritmo está convergindo para um mínimo.  \n",
    "Oscilações ou estagnação precoce podem indicar que a taxa de aprendizado está inadequada ou que o ponto inicial levou a um mínimo local raso.\n",
    "\n",
    "![Imagem4](ex4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0658f7a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
