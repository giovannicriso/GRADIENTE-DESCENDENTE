Nesta pasta se encontra a primeira tarefa de Fisica computacional. 

# Algoritmos de Gradiente Descendente

Este projeto contÃ©m implementaÃ§Ãµes do algoritmo de **gradiente descendente** para diferentes funÃ§Ãµes objetivo. O objetivo Ã© visualizar o comportamento do algoritmo com diferentes taxas de aprendizado e configuraÃ§Ãµes iniciais.

---

## ğŸ§® ExercÃ­cio 1

Implemente o algoritmo de gradiente descendente para encontrar o mÃ­nimo da funÃ§Ã£o:

\[
U(x) = x^2 - 1
\]

- **Taxa de aprendizado**: \(\alpha = 0.1\)  
- **TolerÃ¢ncia**: \(\epsilon = 0.01\)  
- **MÃ¡ximo de iteraÃ§Ãµes**: 1000  
- **CondiÃ§Ã£o inicial**: \(x_0 = 5\)

ğŸ“‰ **Tarefa**:  
- Ilustre o algoritmo com um grÃ¡fico da funÃ§Ã£o \(U(x)\) e a trajetÃ³ria da partÃ­cula.
- Varie os parÃ¢metros \(\alpha\), \(\epsilon\) e \(x_0\) para ver como afetam a convergÃªncia.

  **Resultado**:

  ![U(x) = x^2 - 1](img/EX1.PNG)

---

## ğŸ§® ExercÃ­cio 2

Repita o exercÃ­cio 1 para a funÃ§Ã£o:

\[
U(x) = x^2(x - 1)(x + 1)
\]

- **CondiÃ§Ã£o inicial**: \(x_0 = 2\)

ğŸ“‰ **Tarefa**:  
- Ajuste a taxa de aprendizado \(\alpha\) para fazer o algoritmo convergir ora para um mÃ­nimo, ora para outro.
- **ReflexÃ£o**: O que vocÃª conclui sobre a influÃªncia de \(\alpha\) na convergÃªncia para mÃ­nimos diferentes?

  **Resultado**:

  ![U(x) = x^2(x - 1)(x + 1)](img/ex2.PNG)

---

## ğŸ§® ExercÃ­cio 3

Agora manipule a funÃ§Ã£o anterior somando uma reta:

\[
U(x) = x^2(x - 1)(x + 1) + \frac{x}{4}
\]

ğŸ“‰ **Tarefa**:  
- Repita o processo do exercÃ­cio 2.
- **ReflexÃ£o**: Como a adiÃ§Ã£o de um termo linear afeta a convergÃªncia e a escolha da taxa de aprendizado \(\alpha\)? 

  **Resultado**:

  ![U(x) = x^2(x - 1)(x + 1) + x/4 ](img/ex3.PNG)

---

## ğŸ§® ExercÃ­cio 4

Considere agora uma funÃ§Ã£o bidimensional:

\[
U(\vec{r}) = U(x, y) = \sin(x)\cos(y) + \frac{2(xy)^2}{1000}
\]

A funÃ§Ã£o possui **mÃºltiplos mÃ­nimos locais**.

ğŸ“ˆ **VisualizaÃ§Ã£o**:

1. **GrÃ¡fico de contorno**:
   - Use `plt.imshow` ou `plt.pcolormesh` para desenhar a funÃ§Ã£o.
   - Sobreponha a trajetÃ³ria da partÃ­cula no grÃ¡fico.

2. **GrÃ¡fico de convergÃªncia**:
   - Plote o valor de \(U(x_n, y_n)\) em cada iteraÃ§Ã£o \(n\) (semelhante a "epochs" em redes neurais).

ğŸ” **ParÃ¢metros para explorar**:
- CondiÃ§Ãµes iniciais: \((x_0, y_0)\)
- Taxa de aprendizado \(\alpha\)

ğŸ’¬ **ReflexÃµes**:
- O que acontece ao aumentar/diminuir muito \(\alpha\)?
- VocÃª consegue atingir o **mÃ­nimo global**?

   **Resultado**:

 ![U(r) = U(x, y) = sin(x)cos(y) + 2(xy)^2 / 1000](img/ex4.PNG)


---

## ğŸ“¦ Requisitos

- Python 3
- Bibliotecas: `numpy`, `matplotlib`

Instale com:

```bash
pip install numpy matplotlib
