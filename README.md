Nesta pasta se encontra a primeira tarefa de Fisica computacional. 

# Algoritmos de Gradiente Descendente

Este projeto cont√©m implementa√ß√µes do algoritmo de **gradiente descendente** para diferentes fun√ß√µes objetivo. O objetivo √© visualizar o comportamento do algoritmo com diferentes taxas de aprendizado e configura√ß√µes iniciais.

---

## üßÆ Exerc√≠cio 1

Implemente o algoritmo de gradiente descendente para encontrar o m√≠nimo da fun√ß√£o:

\[
U(x) = x^2 - 1
\]

- **Taxa de aprendizado**: \(\alpha = 0.1\)  
- **Toler√¢ncia**: \(\epsilon = 0.01\)  
- **M√°ximo de itera√ß√µes**: 1000  
- **Condi√ß√£o inicial**: \(x_0 = 5\)

üìâ **Tarefa**:  
- Ilustre o algoritmo com um gr√°fico da fun√ß√£o \(U(x)\) e a trajet√≥ria da part√≠cula.
- Varie os par√¢metros \(\alpha\), \(\epsilon\) e \(x_0\) para ver como afetam a converg√™ncia.

  **Resultado**: A fun√ß√£o √© uma parabola com concavidade para cima e o algoritmo sempre converge para o m√≠nimo global desde que alpha n√£o seja excessivamente grande. Uma taxa de aprendizado muito alta pode causar instabilidades, fazendo o ponto ir para o outro extremo da parabola, por√©m o m√≠nimo √© alcan√ßado na maioria dos casos. Na imagem abaixo, temos a implementa√ß√£o do gradiente descendente para encontrar o minimo da fun√ß√£o. Nota que os pontos azuis correspondem a passos cujos parametros alpha s√£o pequeno e os vermelhos temos valores de alpha grandes.

 Fun√ß√£o usada: `U(x) = x¬≤ - 1`  
![Gr√°fico de U(x)](EX1.PNG)

---

## üßÆ Exerc√≠cio 2

Repita o exerc√≠cio 1 para a fun√ß√£o:

\[
U(x) = x^2(x - 1)(x + 1)
\]

- **Condi√ß√£o inicial**: \(x_0 = 2\)

üìâ **Tarefa**:  
- Ajuste a taxa de aprendizado \(\alpha\) para fazer o algoritmo convergir ora para um m√≠nimo, ora para outro.
- **Reflex√£o**: O que voc√™ conclui sobre a influ√™ncia de \(\alpha\) na converg√™ncia para m√≠nimos diferentes?

  **Resultado**: O gr√°fico acima ilustra a aplica√ß√£o do gradiente descendente na fun√ß√£o ( f_2(x) = x^4 - x^2 ). A curva verde representa a fun√ß√£o a ser minimizada. Observa-se que, para um valor pequeno de alpha (pontos azuis), o algoritmo converge de forma lenta, por√©m est√°vel, at√© um m√≠nimo local. J√° para valores altos de ( \alpha ) (pontos vermelhos), a trajet√≥ria se torna inst√°vel, com oscila√ß√µes e desvios significativos.

Al√©m disso, como a fun√ß√£o possui mais de um ponto de m√≠nimo, a posi√ß√£o inicial influencia fortemente o resultado final: dependendo de onde o algoritmo come√ßa, ele pode convergir para diferentes m√≠nimos locais ‚Äî ou at√© mesmo n√£o convergir, caso a taxa de aprendizado seja muito alta e cause saltos excessivos.

  ![U(x) = x^2(x - 1)(x + 1)](ex2.PNG)

---

## üßÆ Exerc√≠cio 3

Agora manipule a fun√ß√£o anterior somando uma reta:

\[
U(x) = x^2(x - 1)(x + 1) + \frac{x}{4}
\]

üìâ **Tarefa**:  
- Repita o processo do exerc√≠cio 2.
- **Reflex√£o**: Como a adi√ß√£o de um termo linear afeta a converg√™ncia e a escolha da taxa de aprendizado \(\alpha\)? 

  **Resultado**: Ao adicionarmos o termo linear √† fun√ß√£o, ela deixa de ser sim√©trica e um dos m√≠nimos torna-se mais profundo ‚Äî passando a ser o m√≠nimo global. Isso altera significativamente o comportamento do gradiente descendente.

Notamos que, ao variar o valor de alpha, h√° uma mudan√ßa importante na converg√™ncia:

Para valores grandes de alpha, os passos s√£o largos e, muitas vezes, a trajet√≥ria consegue "saltar" sobre o m√≠nimo local e atingir o m√≠nimo global.
J√° com valores pequenos de alpha, os passos s√£o curtos, o que torna o algoritmo mais suscet√≠vel a ficar preso no m√≠nimo local mais pr√≥ximo da posi√ß√£o inicial.
Al√©m disso, o n√∫mero de passos (itera√ß√µes) tamb√©m influencia o resultado final: dependendo do tamanho dos saltos e da inclina√ß√£o da fun√ß√£o ao longo do caminho, o algoritmo pode terminar em diferentes m√≠nimos. Ou seja, tanto a taxa de aprendizado quanto a quantidade de itera√ß√µes s√£o fatores cruciais para determinar o ponto de converg√™ncia.

  ![U(x) = x^2(x - 1)(x + 1) + x/4 ](ex3.PNG)

---

## üßÆ Exerc√≠cio 4

Considere agora uma fun√ß√£o bidimensional:

\[
U(\vec{r}) = U(x, y) = \sin(x)\cos(y) + \frac{2(xy)^2}{1000}
\]

A fun√ß√£o possui **m√∫ltiplos m√≠nimos locais**.

üìà **Visualiza√ß√£o**:

1. **Gr√°fico de contorno**:
   - Use `plt.imshow` ou `plt.pcolormesh` para desenhar a fun√ß√£o.
   - Sobreponha a trajet√≥ria da part√≠cula no gr√°fico.

2. **Gr√°fico de converg√™ncia**:
   - Plote o valor de \(U(x_n, y_n)\) em cada itera√ß√£o \(n\) (semelhante a "epochs" em redes neurais).

üîÅ **Par√¢metros para explorar**:
- Condi√ß√µes iniciais: \((x_0, y_0)\)
- Taxa de aprendizado \(\alpha\)

üí¨ **Reflex√µes**:
- O que acontece ao aumentar/diminuir muito \(\alpha\)?
- Voc√™ consegue atingir o **m√≠nimo global**?

   **Resultado**:  Gr√°fico de Contorno com Trajet√≥ria (√† esquerda)
Este gr√°fico mostra as curvas de n√≠vel da fun√ß√£o ( U(x, y) ), representando seu relevo.
A linha vermelha indica a trajet√≥ria percorrida pelo algoritmo de gradiente descendente a partir do ponto inicial.
Se a trajet√≥ria for suave e converge para um ponto est√°vel, isso indica que o algoritmo est√° funcionando corretamente e aproximando-se de um m√≠nimo da fun√ß√£o.

Gr√°fico da Evolu√ß√£o de ( U(x_n, y_n) ) (√† direita)
Este gr√°fico mostra como o valor da fun√ß√£o ( U ) varia ao longo das itera√ß√µes.
Uma curva decrescente e que se estabiliza sugere que o algoritmo est√° convergindo para um m√≠nimo.
Oscila√ß√µes ou estagna√ß√£o precoce podem indicar que a taxa de aprendizado est√° inadequada ou que o ponto inicial levou a um m√≠nimo local raso.

 ![U(r) = U(x, y) = sin(x)cos(y) + 2(xy)^2 / 1000](ex4.PNG)


---

## üì¶ Requisitos

- Python 3
- Bibliotecas: `numpy`, `matplotlib`

Instale com:

```bash
pip install numpy matplotlib
